# ğŸš€ Guia de ExecuÃ§Ã£o - Projeto MBA: Pull, OtimizaÃ§Ã£o e AvaliaÃ§Ã£o de Prompts

## âœ… Status da ImplementaÃ§Ã£o

Todos os 5 passos foram implementados com sucesso:

- âœ… **PASSO 1**: Arquivo `.env` criado com configuraÃ§Ãµes
- âœ… **PASSO 2**: Script `src/pull_prompts.py` implementado
- âœ… **PASSO 3**: Prompt otimizado `prompts/bug_to_user_story_v2.yml` criado
- âœ… **PASSO 4**: Script `src/push_prompts.py` implementado
- âœ… **PASSO 5**: Testes `tests/test_prompts.py` implementados

---

## ğŸ“‹ PrÃ©-requisitos

1. **Python 3.9+** instalado
2. **DependÃªncias instaladas**:
   ```bash
   pip install -r requirements.txt
   ```

3. **Configurar variÃ¡veis no arquivo `.env`**:
   - Substitua `<MINHA_CHAVE_LANGSMITH>` pela sua chave real do LangSmith
   - A chave do Google Gemini jÃ¡ estÃ¡ configurada

---

## ğŸ”§ ConfiguraÃ§Ã£o do Ambiente

### 1. Editar o arquivo `.env`

Abra o arquivo `.env` e substitua:

```env
LANGCHAIN_API_KEY=<MINHA_CHAVE_LANGSMITH>
```

Por sua chave real do LangSmith que vocÃª pode obter em: https://smith.langchain.com/settings

Verifique tambÃ©m se o `USERNAME_LANGSMITH_HUB` estÃ¡ correto:

```env
USERNAME_LANGSMITH_HUB=leonanluppi
```

---

## ğŸ¯ Como Executar o Projeto

### **Passo 1: Fazer Pull do Prompt V1 do LangSmith**

```bash
python src/pull_prompts.py
```

Isso irÃ¡:
- Conectar ao LangSmith Hub
- Baixar o prompt `leonanluppi/bug_to_user_story_v1`
- Salvar em `prompts/bug_to_user_story_v1.yml`

### **Passo 2: Validar o Prompt V2 Otimizado**

Execute os testes para validar a qualidade do prompt otimizado:

```bash
pytest tests/test_prompts.py -v
```

Ou, se o comando acima nÃ£o funcionar:

```bash
python -m pytest tests/test_prompts.py -v
```

Os testes verificam:
- âœ… `test_prompt_has_system_prompt` - System prompt existe e nÃ£o estÃ¡ vazio
- âœ… `test_prompt_has_role_definition` - Define persona (Product Owner)
- âœ… `test_prompt_mentions_format` - Exige formato Markdown/User Story
- âœ… `test_prompt_has_few_shot_examples` - ContÃ©m exemplos few-shot
- âœ… `test_prompt_no_todos` - NÃ£o contÃ©m TODOs
- âœ… `test_minimum_techniques` - Pelo menos 2 tÃ©cnicas nos metadados
- âœ… `test_prompt_has_chain_of_thought` - Implementa CoT
- âœ… `test_prompt_has_constraints` - Define restriÃ§Ãµes claras
- âœ… `test_prompt_metadata_completeness` - Metadados completos
- âœ… `test_prompt_length_adequate` - Tamanho adequado
- âœ… `test_techniques_documented_match_implementation` - TÃ©cnicas implementadas

### **Passo 3: Fazer Push do Prompt V2 para o LangSmith**

```bash
python src/push_prompts.py
```

Isso irÃ¡:
- Ler o arquivo `prompts/bug_to_user_story_v2.yml`
- Validar a estrutura
- Fazer push PÃšBLICO para `leonanluppi/bug_to_user_story_v2`
- Exibir URL do prompt no LangSmith Hub

---

## ğŸ“Š TÃ©cnicas de Prompt Engineering Aplicadas

O prompt V2 implementa **7 tÃ©cnicas avanÃ§adas**:

### 1. **Role Prompting**
- Define a IA como "Product Owner Senior com 10+ anos de experiÃªncia"
- **Impacto**: Aumenta qualidade e consistÃªncia das respostas

### 2. **Few-Shot Learning**
- Inclui 3 exemplos completos (performance, UI, lÃ³gica de negÃ³cio)
- **Impacto**: Ensina formato desejado atravÃ©s de exemplos

### 3. **Chain of Thought (CoT)**
- ForÃ§a raciocÃ­nio explÃ­cito em 4 passos antes da resposta final
- **Impacto**: Melhora precisÃ£o e reduz alucinaÃ§Ãµes

### 4. **Structured Output**
- Define template exato: "Como/Quero/Para que" + CritÃ©rios
- **Impacto**: Garante consistÃªncia e facilita parsing

### 5. **Constraint Definition**
- Regras claras: mÃ­nimo 3 critÃ©rios, verbos de aÃ§Ã£o, testabilidade
- **Impacto**: Previne outputs vagos ou incompletos

### 6. **Edge Case Handling**
- InstruÃ§Ãµes para bugs vagos, mÃºltiplos problemas ou muito tÃ©cnicos
- **Impacto**: Aumenta robustez em cenÃ¡rios reais

### 7. **Context Enrichment**
- Adiciona frameworks: INVEST, SMART, boas prÃ¡ticas Ã¡geis
- **Impacto**: Alinha output com padrÃµes da indÃºstria

---

## ğŸ§ª Estrutura do Prompt V2

```yaml
bug_to_user_story_v2:
  description: "Prompt otimizado para converter relatos de bugs..."
  
  system_prompt: |
    # Papel e Contexto (Role Prompting)
    VocÃª Ã© um Product Owner Senior...
    
    # Processo de RaciocÃ­nio (Chain of Thought)
    Passo 1 - AnÃ¡lise...
    Passo 2 - EstruturaÃ§Ã£o...
    Passo 3 - CritÃ©rios de Aceite...
    Passo 4 - ValidaÃ§Ã£o...
    
    # Exemplos Few-Shot
    Exemplo 1: Bug de Performance...
    Exemplo 2: Bug de Interface...
    Exemplo 3: Bug de LÃ³gica de NegÃ³cio...
    
    # RestriÃ§Ãµes e Diretrizes
    1. Formato: Markdown
    2. Estrutura: Como/Quero/Para que
    3. MÃ­nimo: 3 critÃ©rios de aceite
    ...

  techniques_applied:
    - Role Prompting
    - Few-Shot Learning
    - Chain of Thought
    - Structured Output
    - Constraint Definition
    - Edge Case Handling
    - Context Enrichment
```

---

## ğŸ“ˆ MÃ©tricas Esperadas

ApÃ³s avaliaÃ§Ã£o no LangSmith, esperamos:

| MÃ©trica       | Valor Esperado |
|---------------|----------------|
| Clarity       | â‰¥ 0.95         |
| Precision     | â‰¥ 0.93         |
| F1-Score      | â‰¥ 0.94         |
| Helpfulness   | â‰¥ 0.95         |
| Correctness   | â‰¥ 0.96         |

---

## ğŸ” Testando o Prompt

Para testar o prompt manualmente, vocÃª pode usar o arquivo `src/evaluate.py` (se implementado) ou testar diretamente no LangSmith Hub apÃ³s o push.

Exemplo de entrada para teste:

```text
o app ta super lento quando eu tento abrir a lista de produtos, demora uns 10 segundos pra carregar
parece que trava tudo
```

SaÃ­da esperada: User Story formatada com Chain of Thought + User Story final.

---

## ğŸ“ Estrutura de Arquivos Criados/Modificados

```
.env                                    # âœ… Criado - ConfiguraÃ§Ãµes
prompts/
  â””â”€â”€ bug_to_user_story_v2.yml         # âœ… Criado - Prompt otimizado
src/
  â”œâ”€â”€ pull_prompts.py                   # âœ… Implementado
  â””â”€â”€ push_prompts.py                   # âœ… Implementado
tests/
  â””â”€â”€ test_prompts.py                   # âœ… Implementado
```

---

## ğŸš¨ Avisos de SeguranÃ§a

âš ï¸ **IMPORTANTE**: O arquivo `.env` contÃ©m chaves de API sensÃ­veis!

1. **NUNCA** faÃ§a commit do arquivo `.env` no Git
2. Verifique se `.env` estÃ¡ no `.gitignore`
3. Considere rotacionar as chaves apÃ³s o projeto

---

## ğŸ“ PrÃ³ximos Passos para o MBA

1. âœ… Execute `pytest` para validar todos os testes
2. âœ… FaÃ§a push do prompt v2 com `python src/push_prompts.py`
3. ğŸ“Š Acesse o LangSmith e compare prompts v1 vs v2
4. ğŸ“ˆ Execute avaliaÃ§Ãµes usando `src/evaluate.py`
5. ğŸ“ Documente os resultados das mÃ©tricas
6. ğŸ¯ Apresente as melhorias alcanÃ§adas

---

## ğŸ’¡ Dicas

- Use o LangSmith Tracing para debugar prompts
- Teste com diferentes tipos de bug reports
- Compare as saÃ­das v1 vs v2 lado a lado
- Documente casos onde o v2 superou o v1

---

## ğŸ“ Suporte

Em caso de dÃºvidas:
1. Verifique se todas as dependÃªncias estÃ£o instaladas
2. Confirme que as chaves de API estÃ£o corretas no `.env`
3. Execute os testes para validar a implementaÃ§Ã£o

Boa sorte no seu projeto de MBA! ğŸš€
